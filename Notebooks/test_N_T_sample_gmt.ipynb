{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edea923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statisUtils as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import loguniform, lognorm\n",
    "from scipy import stats\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import ABCSampler as abcSampler\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5855df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # initial N value\n",
    "T = 5 # fixed T value\n",
    "incr_N = 50 # increment factor for N\n",
    "\n",
    "MAX_N = 100 # maximum value for N\n",
    "\n",
    "output_dir = 'test_gtm_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d8bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast = pd.read_csv('data/cast_genes_count.csv', header=None, index_col=[0]) # gene x cells\n",
    "df_c57 = pd.read_csv('data/c57_genes_count.csv', header=None, index_col=[0]) # gene x cells\n",
    "\n",
    "df = df_cast + df_c57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc6fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(result):\n",
    "    result_flatten = result.flatten()\n",
    "    temp_df = pd.DataFrame([x for x in result_flatten])\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ea0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bf_and_bs(temp_df):\n",
    "    \"\"\"\n",
    "    input is the dataframe containing the parameters as columns.\n",
    "    need column named 'koff', 'roff', 'kon', 'ron' \n",
    "    \n",
    "    compute burst frequency and burst size from the parameters\n",
    "    \"\"\"\n",
    "    temp_df['tau_off']= temp_df['kon']/temp_df['ron']\n",
    "    temp_df['tau_on'] = temp_df['koff']/temp_df['roff']\n",
    "    temp_df['bf'] = 1./(temp_df['tau_on'] + temp_df['tau_off'])\n",
    "    temp_df['bs'] = temp_df['mu'] * temp_df['tau_on']\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c055852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_bf_and_bs(temp_df):\n",
    "    temp_df = get_bf_and_bs(temp_df)\n",
    "    temp_df['log_kon'] = [np.log10(x) for x in temp_df['kon']]\n",
    "    temp_df['log_koff'] = [np.log10(x) for x in temp_df['koff']]\n",
    "    temp_df['log_bs'] = [np.log10(x) for x in temp_df['bs']]\n",
    "    temp_df['log_bf'] = [np.log10(x) for x in temp_df['bf']]\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7036ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_parameters(temp_df, density_kernel_name=None, save_kde=False):\n",
    "    \"\"\"\n",
    "    return the index for the best parameters.\n",
    "    \n",
    "    if density_kernel_name is None , we recompute the gaussian kde and if save_kde is a str. \n",
    "    Save the kde in df using save_kde as column name\n",
    "    \"\"\"\n",
    "    \n",
    "    if density_kernel_name is None:\n",
    "        # Calculate the point density\n",
    "        xy = np.vstack([temp_df['bs'],temp_df['bf']])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        if save_kde is not False:\n",
    "            temp_df[save_kde] = z\n",
    "            \n",
    "    else:\n",
    "        z = temp_df[density_kernel_name]\n",
    "    \n",
    "    return(np.where(z == np.amax(z))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db35e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name = 'Fn1'\n",
    "row = row = df.loc[gene_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d4bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognpdf(x, mu, sigma):\n",
    "    shape  = sigma\n",
    "    loc    = 0\n",
    "    scale  = np.exp(mu)\n",
    "    return lognorm.pdf(x, shape, loc, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf91e0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Processing gene: Fn1, N= 20, T= 5\n",
      "Finish Processing gene: Fn1, N= 20, T= 5, time= 9.617774486541748\n",
      "\n",
      "Start Processing gene: Fn1, N= 70, T= 5\n",
      "Finish Processing gene: Fn1, N= 70, T= 5, time= 79.90861773490906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while N <= MAX_N:\n",
    "    \n",
    "    start_processing = time.time()\n",
    "    print(f\"Start Processing gene: {gene_name}, N= {N}, T= {T}\")\n",
    "    \n",
    "    data = np.array(row)\n",
    "\n",
    "    gene = data[data>=0]\n",
    "    k = int(0.95*len(gene))\n",
    "    gene = gene[np.argpartition(gene, k)[:k]]\n",
    "    gene = np.sort(gene)\n",
    "\n",
    "    data_mean = np.mean(gene);\n",
    "    data_var = np.var(gene);\n",
    "    data_noise = data_var/(data_mean**2);\n",
    "\n",
    "    statis_data = utils.statisData(gene);\n",
    "\n",
    "    rho = lambda s: np.sqrt(\n",
    "                np.sum(\n",
    "                    np.log(statis_data/(s))**2\n",
    "                )\n",
    "    )\n",
    "\n",
    "    f = lambda k: utils.statisGTM(k,4)\n",
    "    epsilon = 1\n",
    "    \n",
    "    prior = lambda: np.array([\n",
    "            5 * np.random.uniform(), # kon ~ U[0,5]\n",
    "            10**random.uniform(-1,1), # ron ~ logU[-1,1] base 10\n",
    "            5 * np.random.uniform(), # koff ~ U[0,5]\n",
    "            10**random.uniform(-1,1), # roff ~ logU[-1,1] base 10 \n",
    "            100 * np.random.uniform(), # rsyn ~ U[0,50] ?? in paper assumes upper bound 50, but in code is 100\n",
    "            1]) # rdeg=1\n",
    "\n",
    "    proposal_sigma = 0.2\n",
    "\n",
    "    proposal = lambda x: np.random.lognormal(x,proposal_sigma)\n",
    "\n",
    "    proposal_pdf = lambda kon_post,kon_prior,ron_post,ron_prior,koff_post,koff_prior,roff_post,roff_prior,mu_post,mu_prior: \\\n",
    "    lognpdf(mu_post,np.log(mu_prior),proposal_sigma) * lognpdf(kon_post,np.log(kon_prior),proposal_sigma) \\\n",
    "    * lognpdf(ron_post,np.log(ron_prior),proposal_sigma) * lognpdf(koff_post,np.log(koff_prior),proposal_sigma) \\\n",
    "    * lognpdf(roff_post,np.log(roff_prior),proposal_sigma)\n",
    "    \n",
    "    result, flag = abcSampler.ABCSMCSampler(N,prior,f,rho,epsilon,T,proposal,proposal_pdf,gene_name)\n",
    "    \n",
    "    np.save(f'{output_dir}/posterior/gene_{gene_name}_N{N}_T{T}.npy', np.array([gene_name, gene, result], dtype=object))\n",
    "    \n",
    "    end_processing = time.time()\n",
    "    total_processing = end_processing - start_processing\n",
    "    print(f\"Finish Processing gene: {gene_name}, N= {N}, T= {T}, time= {total_processing}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # save best params\n",
    "    result_df = get_df(result)\n",
    "    result_df = get_log_bf_and_bs(result_df)\n",
    "    \n",
    "    bp = best_parameters(result_df, save_kde='density_kernel')\n",
    "    bp_data = result_df.iloc[bp].copy()\n",
    "    \n",
    "    bp_data = bp_data.to_frame().transpose().rename(index={bp: f'N{N}_T{T}'})\n",
    "    \n",
    "    # save number of samples and process time\n",
    "    samp_arr = bp_data.index[0].split('_')\n",
    "    num_samples = int(samp_arr[0][1:]) * int(samp_arr[1][1:])\n",
    "    bp_data['num_samples'] = num_samples\n",
    "    bp_data['process_time'] = total_processing\n",
    "    \n",
    "    # save the data\n",
    "    if os.path.exists(f'{output_dir}/gtm_N_T_estimations.csv'):\n",
    "        df_NT = pd.read_csv(f'{output_dir}/gtm_N_T_estimations.csv', index_col=[0])\n",
    "        df_new = pd.concat([df_NT, bp_data])\n",
    "        df_new.to_csv(f'{output_dir}/gtm_N_T_estimations.csv')\n",
    "    else:\n",
    "        bp_data.to_csv(f'{output_dir}/gtm_N_T_estimations.csv')\n",
    "\n",
    "\n",
    "\n",
    "    N += incr_N\n",
    "print(\"End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
